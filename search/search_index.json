{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"bootstrapx","text":"<p>Production-grade uncertainty estimation for Python.</p> <p>14 bootstrap methods \u00b7 Numba JIT \u00b7 Optional CUDA GPU \u00b7 Memory-safe batching</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import numpy as np\nfrom bootstrapx import bootstrap\n\ndata = np.random.default_rng(42).normal(5, 2, size=200)\nresult = bootstrap(data, np.mean)\nprint(result)\n# BootstrapResult(method='bca', theta_hat=4.94, se=0.13, CI=[4.70, 5.19])\n</code></pre>"},{"location":"#why-bootstrapx","title":"Why bootstrapx?","text":"Feature <code>scipy.stats.bootstrap</code> R <code>boot</code> bootstrapx BCa interval \u2705 \u2705 \u2705 Studentized (bootstrap-t) \u274c \u2705 \u2705 Poisson / Bernoulli weights \u274c \u274c \u2705 Time-series methods (6 types) \u274c Partial \u2705 Wild bootstrap \u274c \u274c \u2705 Cluster / Stratified \u274c Partial \u2705 Numba JIT acceleration \u274c N/A \u2705 GPU (CUDA) support \u274c \u274c \u2705 Generator-based batching \u274c \u274c \u2705"},{"location":"#install","title":"Install","text":"<pre><code>pip install bootstrapx\n</code></pre>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>See <code>benchmarks/</code> directory for reproducible benchmark scripts.</p> <p>Results on a typical development machine (Apple M1, Python 3.12):</p>"},{"location":"benchmarks/#speed-bootstrapx-vs-scipystatsbootstrap","title":"Speed: bootstrapx vs scipy.stats.bootstrap","text":"N Method Scipy (s) Bx-Vanilla (s) Bx-Numba (s) Speedup 500 BCa 0.04 0.04 0.94 0.0x 1,000 BCa 0.07 0.07 0.05 1.3x 5,000 BCa 0.80 0.26 0.27 3.0x 10,000 Percentile 1.43 0.46 0.49 2.9x 50,000 Percentile 7.29 2.19 2.01 3.6x 100,000 Percentile 54.34 4.51 3.99 13.6x <p>Key takeaway: - For small datasets (\\(N &lt; 1000\\)), overhead dominates, performance is comparable. - For medium datasets (\\(N \\approx 5000\\)), bootstrapx is 3x faster. - For large datasets (\\(N = 100k\\)), bootstrapx is 13.6x faster due to efficient memory management and Numba compilation, while Scipy slows down significantly.</p>"},{"location":"benchmarks/#coverage-accuracy-large-sample-n1000","title":"Coverage Accuracy (Large Sample, N=1000)","text":"<p>Monte Carlo simulation (500 runs, \\(N=1000\\) observations per sample). Nominal confidence level: 95%.</p> Data Distribution Percentile Basic BCa Normal \\(N(5, 4)\\) 94.6% 94.8% 94.8% Skewed \\(Exp(2)\\) 95.2% 95.6% 95.0% Heavy-Tailed \\(t(3)\\) 94.0% 94.6% 94.0% <p>Analysis: - All methods converge to the nominal 95% level on large samples. - BCa achieves exactly 95.0% on the skewed Exponential distribution, confirming its theoretical advantage in handling asymmetry. - The variations (e.g., 94.6% vs 95.0%) are within the expected Monte Carlo error margin (~1%).</p> <p>These results demonstrate that bootstrapx provides production-grade statistical correctness alongside significant performance improvements.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>See CHANGELOG.md in the repository root.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install bootstrapx-lib\n\n# With GPU support\npip install \"bootstrapx-lib[cuda]\"\n\n# For development\npip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":"<pre><code>import numpy as np\nfrom bootstrapx import bootstrap\n\ndata = np.random.default_rng(42).normal(5, 2, size=200)\n\n# BCa (default) \u2014 best general-purpose method\nresult = bootstrap(data, np.mean)\nprint(f\"Mean: {result.theta_hat:.3f}\")\nprint(f\"95% CI: [{result.confidence_interval.low:.3f}, {result.confidence_interval.high:.3f}]\")\nprint(f\"SE: {result.standard_error:.3f}\")\n</code></pre>"},{"location":"getting-started/#comparing-ci-methods","title":"Comparing CI Methods","text":"<pre><code>data = np.random.default_rng(0).exponential(2.0, size=150)\n\nfor method in [\"percentile\", \"basic\", \"bca\"]:\n    r = bootstrap(data, np.mean, method=method, n_resamples=9999, random_state=42)\n    ci = r.confidence_interval\n    print(f\"{method:&gt;12s}: [{ci.low:.3f}, {ci.high:.3f}]  se={r.standard_error:.3f}\")\n</code></pre>"},{"location":"getting-started/#time-series","title":"Time Series","text":"<pre><code>ts = np.cumsum(np.random.default_rng(0).standard_normal(500))\nresult = bootstrap(ts, np.mean, method=\"stationary\", mean_block=15.0)\n</code></pre>"},{"location":"getting-started/#custom-statistics","title":"Custom Statistics","text":"<pre><code>def iqr(x):\n    return float(np.percentile(x, 75) - np.percentile(x, 25))\n\nresult = bootstrap(data, iqr, method=\"bca\", n_resamples=9999)\n</code></pre>"},{"location":"getting-started/#reproducibility","title":"Reproducibility","text":"<pre><code>r1 = bootstrap(data, np.mean, random_state=42)\nr2 = bootstrap(data, np.mean, random_state=42)\nassert np.array_equal(r1.bootstrap_distribution, r2.bootstrap_distribution)\n</code></pre>"},{"location":"methods/","title":"Methods Guide","text":""},{"location":"methods/#iid-methods","title":"IID Methods","text":""},{"location":"methods/#percentile","title":"Percentile","text":"<p>Standard quantile-based CI. Simple but can have poor coverage for skewed distributions.</p>"},{"location":"methods/#basic-reverse-percentile","title":"Basic (Reverse Percentile)","text":"\\[CI = [2\\hat{\\theta} - q_{1-\\alpha/2},\\; 2\\hat{\\theta} - q_{\\alpha/2}]\\]"},{"location":"methods/#bca-bias-corrected-and-accelerated","title":"BCa (Bias-Corrected and Accelerated)","text":"<p>The recommended default. Corrects for bias and skewness using jackknife acceleration:</p> \\[\\hat{a} = \\frac{\\sum_{i=1}^{n}(\\hat{\\theta}_{(\\cdot)} - \\hat{\\theta}_{(i)})^3}{6\\left[\\sum_{i=1}^{n}(\\hat{\\theta}_{(\\cdot)} - \\hat{\\theta}_{(i)})^2\\right]^{3/2}}\\]"},{"location":"methods/#studentized-bootstrap-t","title":"Studentized (Bootstrap-t)","text":"<p>Uses pivotal quantity \\(t^* = (\\hat{\\theta}^* - \\hat{\\theta}) / \\hat{se}^*\\) with nested bootstrap for SE.</p>"},{"location":"methods/#poisson-bootstrap","title":"Poisson Bootstrap","text":"<p>Weighted resampling with \\(W \\sim \\text{Poisson}(1)\\). Ideal for streaming/online algorithms.</p>"},{"location":"methods/#bernoulli-bootstrap","title":"Bernoulli Bootstrap","text":"<p>Binary weights \\(W \\sim \\text{Bernoulli}(p)\\). Useful for specific ML applications.</p>"},{"location":"methods/#subsampling-m-out-of-n","title":"Subsampling (m-out-of-n)","text":"<p>Sampling without replacement, size \\(m &lt; n\\). Required for non-regular statistics (max, min).</p>"},{"location":"methods/#time-series-methods","title":"Time Series Methods","text":""},{"location":"methods/#moving-block-bootstrap-mbb","title":"Moving Block Bootstrap (MBB)","text":"<p>Overlapping fixed-length blocks. Set <code>block_length</code> based on autocorrelation structure.</p>"},{"location":"methods/#circular-block-bootstrap-cbb","title":"Circular Block Bootstrap (CBB)","text":"<p>Wraps data circularly to eliminate edge effects. Same block logic as MBB.</p>"},{"location":"methods/#stationary-bootstrap-politis-romano","title":"Stationary Bootstrap (Politis &amp; Romano)","text":"<p>Random block lengths \\(L \\sim \\text{Geometric}(1/\\bar{L})\\) where \\(\\bar{L}\\) = <code>mean_block</code>.</p>"},{"location":"methods/#tapered-block-bootstrap","title":"Tapered Block Bootstrap","text":"<p>Applies a tapering window (Tukey, Hanning, etc.) to each block. For spectral density estimation.</p>"},{"location":"methods/#ar-sieve-bootstrap","title":"AR-Sieve Bootstrap","text":"<p>Fits AR(p) model \u2192 extracts residuals \u2192 resamples residuals \u2192 reconstructs series.</p>"},{"location":"methods/#wild-bootstrap","title":"Wild Bootstrap","text":"<p>$\\(y_t^* = \\hat{y}_t + \\hat{\\varepsilon}_t \\cdot v_t\\)$ where \\(v_t\\) is Rademacher (\u00b11) or Mammen two-point. Handles heteroskedasticity.</p>"},{"location":"methods/#hierarchical-methods","title":"Hierarchical Methods","text":""},{"location":"methods/#cluster-bootstrap","title":"Cluster Bootstrap","text":"<p>Resamples entire clusters (groups), preserving within-group correlation structure.</p>"},{"location":"methods/#stratified-bootstrap","title":"Stratified Bootstrap","text":"<p>Resamples within each stratum independently, preserving class proportions.</p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#main-entry-point","title":"Main Entry Point","text":""},{"location":"reference/#bootstrapx.api.bootstrap","title":"<code>bootstrapx.api.bootstrap(data, statistic, *, method='bca', n_resamples=9999, batch_size=None, confidence_level=0.95, backend='auto', random_state=None, n_jobs=1, **kwargs)</code>","text":""},{"location":"reference/#bootstrapx.api.BootstrapResult","title":"<code>bootstrapx.api.BootstrapResult</code>  <code>dataclass</code>","text":"Source code in <code>bootstrapx/api.py</code> <pre><code>@dataclass\nclass BootstrapResult:\n    confidence_interval: ConfidenceInterval\n    bootstrap_distribution: np.ndarray\n    theta_hat: float\n    standard_error: float\n    n_resamples: int\n    method: str\n    extra: dict[str, Any] = field(default_factory=dict)\n\n    def __repr__(self) -&gt; str:\n        ci = self.confidence_interval\n        return (\n            f\"BootstrapResult(method={self.method!r}, \"\n            f\"theta_hat={self.theta_hat:.6g}, \"\n            f\"se={self.standard_error:.6g}, \"\n            f\"CI=[{ci.low:.6g}, {ci.high:.6g}])\"\n        )\n</code></pre>"},{"location":"reference/#confidence-intervals","title":"Confidence Intervals","text":""},{"location":"reference/#bootstrapx.stats.confidence.percentile_interval","title":"<code>bootstrapx.stats.confidence.percentile_interval(boot_stats, confidence_level=0.95)</code>","text":"Source code in <code>bootstrapx/stats/confidence.py</code> <pre><code>def percentile_interval(boot_stats, confidence_level=0.95):\n    alpha = 1.0 - confidence_level\n    return ConfidenceInterval(\n        low=float(np.percentile(boot_stats, 100 * alpha / 2)),\n        high=float(np.percentile(boot_stats, 100 * (1 - alpha / 2))),\n        method=\"percentile\",\n    )\n</code></pre>"},{"location":"reference/#bootstrapx.stats.confidence.basic_interval","title":"<code>bootstrapx.stats.confidence.basic_interval(boot_stats, theta_hat, confidence_level=0.95)</code>","text":"Source code in <code>bootstrapx/stats/confidence.py</code> <pre><code>def basic_interval(boot_stats, theta_hat, confidence_level=0.95):\n    alpha = 1.0 - confidence_level\n    q_low = np.percentile(boot_stats, 100 * alpha / 2)\n    q_high = np.percentile(boot_stats, 100 * (1 - alpha / 2))\n    return ConfidenceInterval(\n        low=float(2 * theta_hat - q_high),\n        high=float(2 * theta_hat - q_low),\n        method=\"basic\",\n    )\n</code></pre>"},{"location":"reference/#bootstrapx.stats.confidence.bca_interval","title":"<code>bootstrapx.stats.confidence.bca_interval(boot_stats, data, statistic, theta_hat, confidence_level=0.95)</code>","text":"Source code in <code>bootstrapx/stats/confidence.py</code> <pre><code>def bca_interval(boot_stats, data, statistic, theta_hat, confidence_level=0.95):\n    alpha = 1.0 - confidence_level\n\n    # Bias correction z0\n    prop_less = np.mean(boot_stats &lt; theta_hat)\n    # Clip to avoid infinity\n    prop_less = np.clip(prop_less, 1e-10, 1 - 1e-10)\n    z0 = float(sp_stats.norm.ppf(prop_less))\n\n    # Acceleration a\n    jack_stats = _jackknife(data, statistic)\n    mean_jack = jack_stats.mean()\n    diffs = mean_jack - jack_stats\n\n    num = (diffs**3).sum()\n    den = ((diffs**2).sum()) ** 1.5\n\n    a_hat = num / (6 * den) if den != 0 else 0.0\n\n    # Adjusted percentiles\n    def adjust_percentile(z_alpha):\n        num_adj = z0 + z_alpha\n        denom_adj = 1 - a_hat * num_adj\n        return float(sp_stats.norm.cdf(z0 + num_adj / denom_adj))\n\n    p_low = adjust_percentile(sp_stats.norm.ppf(alpha / 2))\n    p_high = adjust_percentile(sp_stats.norm.ppf(1 - alpha / 2))\n\n    return ConfidenceInterval(\n        low=float(np.percentile(boot_stats, 100 * p_low)),\n        high=float(np.percentile(boot_stats, 100 * p_high)),\n        method=\"bca\",\n    )\n</code></pre>"},{"location":"reference/#bootstrapx.stats.confidence.studentized_interval","title":"<code>bootstrapx.stats.confidence.studentized_interval(data, statistic, theta_hat, boot_stats, boot_se, confidence_level=0.95)</code>","text":"Source code in <code>bootstrapx/stats/confidence.py</code> <pre><code>def studentized_interval(\n    data, statistic, theta_hat, boot_stats, boot_se, confidence_level=0.95\n):\n    alpha = 1.0 - confidence_level\n    mask = boot_se &gt; 0\n    t_vals = (boot_stats[mask] - theta_hat) / boot_se[mask]\n\n    t_low = np.percentile(t_vals, 100 * (1 - alpha / 2))\n    t_high = np.percentile(t_vals, 100 * alpha / 2)\n\n    se_hat = np.std(boot_stats, ddof=1)\n\n    return ConfidenceInterval(\n        low=float(theta_hat - t_low * se_hat),\n        high=float(theta_hat - t_high * se_hat),\n        method=\"studentized\",\n    )\n</code></pre>"},{"location":"reference/#utilities","title":"Utilities","text":""},{"location":"reference/#bootstrapx.utils.validate_data","title":"<code>bootstrapx.utils.validate_data(data, *, allow_2d=False)</code>","text":"Source code in <code>bootstrapx/utils.py</code> <pre><code>def validate_data(data, *, allow_2d: bool = False) -&gt; np.ndarray:\n    arr = np.asarray(data)\n    if arr.ndim == 0:\n        raise ValueError(\"Scalar data is not supported.\")\n    if arr.ndim &gt; 2 or (arr.ndim == 2 and not allow_2d):\n        raise ValueError(\n            f\"Expected 1-D array, got shape {arr.shape}. \"\n            \"Pass allow_2d=True for matrix data.\"\n        )\n    if np.any(np.isnan(arr)):\n        raise ValueError(\"Data contains NaN values. Remove or impute them first.\")\n    if arr.shape[0] &lt; 2:\n        raise ValueError(\"Data must have at least 2 observations.\")\n    return arr\n</code></pre>"},{"location":"reference/#bootstrapx.utils.auto_batch_size","title":"<code>bootstrapx.utils.auto_batch_size(n, n_resamples)</code>","text":"Source code in <code>bootstrapx/utils.py</code> <pre><code>def auto_batch_size(n: int, n_resamples: int) -&gt; int:\n    # Heuristic: aim for chunks that fit in L2 cache but huge enough for vectorization\n    # 32k elements per batch is usually a sweet spot for numpy\n    target_elements = 32_768\n    bs = max(1, target_elements // n)\n    return min(bs, n_resamples)\n</code></pre>"},{"location":"reference/#backend","title":"Backend","text":""},{"location":"reference/#bootstrapx.engine.backend.resolve_backend","title":"<code>bootstrapx.engine.backend.resolve_backend(requested='auto')</code>","text":"Source code in <code>bootstrapx/engine/backend.py</code> <pre><code>def resolve_backend(requested: str = \"auto\") -&gt; BackendKind:\n    requested = requested.lower().strip()\n    if requested == \"auto\":\n        if _cuda_available():\n            return BackendKind.NUMBA_CUDA\n        elif _numba_available():\n            return BackendKind.NUMBA_CPU\n        else:\n            return BackendKind.VANILLA\n\n    mapping = {\n        \"numba_cpu\": BackendKind.NUMBA_CPU,\n        \"numba_cuda\": BackendKind.NUMBA_CUDA,\n        \"vanilla\": BackendKind.VANILLA,\n    }\n\n    if requested not in mapping:\n        valid = list(mapping.keys())\n        raise ValueError(f\"Unknown backend {requested!r}. Choose from {valid}.\")\n\n    kind = mapping[requested]\n    if kind is BackendKind.NUMBA_CUDA and not _cuda_available():\n        raise RuntimeError(\"CUDA backend requested but no GPU found.\")\n    return kind\n</code></pre>"},{"location":"reference/#bootstrapx.engine.backend.BackendKind","title":"<code>bootstrapx.engine.backend.BackendKind</code>","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>bootstrapx/engine/backend.py</code> <pre><code>class BackendKind(enum.Enum):\n    NUMBA_CPU = \"numba_cpu\"\n    NUMBA_CUDA = \"numba_cuda\"\n    VANILLA = \"vanilla\"\n</code></pre>"}]}